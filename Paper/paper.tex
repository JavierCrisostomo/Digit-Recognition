\documentclass{article} % For LaTeX2e
\usepackage{nips12submit_e,times}
\usepackage{hyperref}
\usepackage[margin=1.5in]{geometry}
%\documentstyle[nips12submit_09,times,art10]{article} % For LaTeX 2.09


 \title{Digit Recognition: Nearest Neighbors vs. Perceptron}


\author{
Harnoor Singh \\
Department of Computer Science \& Engineering\\
University of Washington \\
\texttt{hsingh@cs.washington.edu} \\
\And
Brian Walker \\
Department of Computer Science \& Engineering \\
University of Washington \\
\texttt{bdwalker@cs.washington.edu} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}
\maketitle

\begin{abstract}

Optical Character Recognition (OCR) is a complex computer science problem which
has several effective machine learning solutions. We implemented the K Nearest
Neighbors (KNN) and Kernelized Perceptron algorithms and compared the
effectiveness of both methods in classifying a testing data set of 28,000
images. Each image is formatted as an array of 768 pixel values, with each value
indicating how dark each pixel was in the image. Both of our algorithms were
trained on a training data set of 42,000 images. We used cross validation to
tune the K value in KNN and to choose a kernel function and dimension value for
Perceptron. Despite its relative simplicity, we found that KNN was more
effective than Perceptron in classifying the digits. The nearest neighbors
algorithm correctly classified 96.857\% of the testing samples on a weighted
neighbors algorithm which looked at 4 neighbors. Our best Perceptron
implementation correctly classified 95.67\% of the testing samples using an
exponential kernel with a $\sigma = 5$. Despite its higher accuracy, the runtime
of KNN was 8x slower than that of the Perceptron.

\end{abstract}

\section{The Problem}

\subsection{Image Data}
Optical Character Recognition (OCR) is a computational problem where a machine
attempts to classify an image of text. We tackled a subset of this problem,
attempting to classify the digits 0-9 from data provided by the Kaggle Digit
Recognition
competition\footnote{\url{http://www.kaggle.com/c/digit-recognizer}}.

The Kaggle data provides two groups of data, 42,000 training samples with labels
and 28,000 unlabeled testing samples. Each training sample contains a 48 pixel
by 48 pixel image containing a handwritten number. The image is represented as
an array of 768 pixel values which represent how dark each pixel of the image
is. Table 1 is an example of a training sample.

\begin{table}[ht]
\textbf{\caption{Subset of Kaggle Data}} % title
\centering 
\begin{tabular}{c | c c c }
Label & Pixel 77 & Pixel 78 & Pixel 79 \\
\hline
8 & 0 & 0 & 0 \\
6 & 89 & 208 & 135 \\ [1ex]
\end{tabular}
\label{table:nonlin}
\end{table}

\section{K Nearest Neighbors (KNN)}

\subsection{Overview}

K Nearest Neighbors is a relatively simple algorithm which often gets surprisingly
good results given its simplicity. Given a testing sample $X$, the algorithm
looks through all the training samples it has previously seen and finds the
\textit{K} most similar samples. The algorithm then implements some form of
voting mechanism among the \textit{K} samples to classify the testing sample as
a digit 0-9. The voting mechanism can either be as straightforward as selecting the
majority label, to something more complicated which involves weighting the
samples based on some distance metric. 

\subsection{Implementation Details}

The first step in implementing KNN is to find the \textit{K} nearest
neighbors. This is accomplished by taking the euclidean distance between the
testing sample we are classifying and every training sample in our training data
set. 

\begin{center}
$Euclidean(TestX, TrainX) = \sum\limits_{i \in TrainX} {(TestX - TrainX_i)^2}$
\end{center}

Because the image data is defined as an array of 768 pixels, $TestX - TrainX_i$
is actually doing a 768 dimension comparison between data points.

Once we identified the \textit{K} nearest neighbors to our testing sample, we
had to use this information to classify the testing point. We considered two
approaches when deciding how to perform this classification.

\subsubsection{Unweighted KNN}

The first method we implemented to classify our testing sample was a simple
majority voting algorithm which selects the majority label from the \textit{K}
closest neighbors. For example, if we ran the nearest neighbors algorithm with
$K = 5$ and 3 of the neighbors had a label of 6, we would classify our testing
sample as a 6.

\subsubsection{Weighted KNN}

Given the \textit{K} nearest neighbors, the weighted version of the algorithm
multiplies each label by a weight which indicates how close it is to our testing
sample. These weights help to emphasize points that are closer to our testing
sample while reducing the impact further away training points have on
classifying our testing sample. 

\subsection{Cross Validation}

Our implementation of KNN has a number of parameters which require
tuning. In particular, we need to decide whether or not to use the weighted
version of our KNN algorithm and how many neighbors to consider when
implementing our algorithm.

To do this, we implemented K folds cross validation using 5,000 training
samples. The reduced training set allowed us to run our algorithm using various
configurations to see which configuration was most accurate.

\begin{table}[ht]
\textbf{\caption{KNN Cross Validation Error Rates}} % title
\centering
\begin{tabular}{c | c c }
K & Unweighted KNN Error & Weighted KNN Error \\
\hline
1 & .077 & .077 \\
2 & .092 & .092 \\
3 & .075 & .075 \\
4 & .078 & .073 \\
5 & .078 & .075 \\
10 & .085 & .079 \\
15 & .095 & .089 \\
20 & .102 & .098 \\ [1ex]
\end{tabular}
\label{table:nonlin}
\end{table}

Our cross validation results suggest that running weighted KNN with $K = 4$
yields the most successful classification rate. One caveat to this is that our
cross validation code ran using 5,000 training samples instead of the 42,000
samples in our full training set. It is possible that data we used to cross
validate is no representative of the full data set.

\subsection{Runtime}

\subsection{Results}

\section{Kernelized Perceptron}
\subsubsection{Overview}

\subsubsection{Implementation Details}

\subsubsection{Results}


\section{Citations, figures, tables, references}
\label{others}

These instructions apply to everyone, regardless of the formatter being used.

\subsection{Citations within the text}

Citations within the text should be numbered consecutively. The corresponding
number is to appear enclosed in square brackets, such as [1] or [2]-[5]. The
corresponding references are to be listed in the same order at the end of the
paper, in the \textbf{References} section. (Note: the standard
\textsc{Bib\TeX} style \texttt{unsrt} produces this.) As to the format of the
references themselves, any style is acceptable as long as it is used
consistently.

As submission is double blind, refer to your own published work in the 
third person. That is, use ``In the previous work of Jones et al.\ [4]'',
not ``In our previous work [4]''. If you cite your other papers that
are not widely available (e.g.\ a journal paper under review), use
anonymous author names in the citation, e.g.\ an author of the
form ``A.\ Anonymous''. 


\subsection{Footnotes}

Indicate footnotes with a number\footnote{Sample of the first footnote} in the
text. Place the footnotes at the bottom of the page on which they appear.
Precede the footnote with a horizontal rule of 2~inches
(12~picas).\footnote{Sample of the second footnote}

\subsection{Figures}

All artwork must be neat, clean, and legible. Lines should be dark
enough for purposes of reproduction; art work should not be
hand-drawn. The figure number and caption always appear after the
figure. Place one line space before the figure caption, and one line
space after the figure. The figure caption is lower case (except for
first word and proper nouns); figures are numbered consecutively.

Make sure the figure caption does not get separated from the figure.
Leave sufficient space to avoid splitting the figure and figure caption.

You may use color figures. 
However, it is best for the
figure captions and the paper body to make sense if the paper is printed
either in black/white or in color.
\begin{figure}[h]
\begin{center}
%\framebox[4.0in]{$\;$}
\fbox{\rule[-.5cm]{0cm}{4cm} \rule[-.5cm]{4cm}{0cm}}
\end{center}
\caption{Sample figure caption.}
\end{figure}

\subsection{Tables}

All tables must be centered, neat, clean and legible. Do not use hand-drawn
tables. The table number and title always appear before the table. See
Table~\ref{sample-table}.

Place one line space before the table title, one line space after the table
title, and one line space after the table. The table title must be lower case
(except for first word and proper nouns); tables are numbered consecutively.

\begin{table}[t]
\caption{Sample table title}
\label{sample-table}
\begin{center}
\begin{tabular}{ll}
\multicolumn{1}{c}{\bf PART}  &\multicolumn{1}{c}{\bf DESCRIPTION}
\\ \hline \\
Dendrite         &Input terminal \\
Axon             &Output terminal \\
Soma             &Cell body (contains cell nucleus) \\
\end{tabular}
\end{center}
\end{table}

\section{Final instructions}
Do not change any aspects of the formatting parameters in the style files.
In particular, do not modify the width or length of the rectangle the text
should fit into, and do not change font sizes (except perhaps in the
\textbf{References} section; see below). Please note that pages should be
numbered.

\section{Preparing PostScript or PDF files}

Please prepare PostScript or PDF files with paper size ``US Letter'', and
not, for example, ``A4''. The -t
letter option on dvips will produce US Letter files.

Fonts were the main cause of problems in the past years. Your PDF file must
only contain Type 1 or Embedded TrueType fonts. Here are a few instructions
to achieve this.

\begin{itemize}

\item You can check which fonts a PDF files uses.  In Acrobat Reader,
select the menu Files$>$Document Properties$>$Fonts and select Show All Fonts. You can
also use the program \verb+pdffonts+ which comes with \verb+xpdf+ and is
available out-of-the-box on most Linux machines.

\item The IEEE has recommendations for generating PDF files whose fonts
are also acceptable for NIPS. Please see
\url{http://www.emfield.org/icuwb2010/downloads/IEEE-PDF-SpecV32.pdf}

\item LaTeX users:

\begin{itemize}

\item Consider directly generating PDF files using \verb+pdflatex+
(especially if you are a MiKTeX user). 
PDF figures must be substituted for EPS figures, however.

\item Otherwise, please generate your PostScript and PDF files with the following commands:
\begin{verbatim} 
dvips mypaper.dvi -t letter -Ppdf -G0 -o mypaper.ps
ps2pdf mypaper.ps mypaper.pdf
\end{verbatim}

Check that the PDF files only contains Type 1 fonts. 
%For the final version, please send us both the Postscript file and
%the PDF file. 

\item xfig "patterned" shapes are implemented with 
bitmap fonts.  Use "solid" shapes instead. 
\item The \verb+\bbold+ package almost always uses bitmap
fonts.  You can try the equivalent AMS Fonts with command
\begin{verbatim}
\usepackage[psamsfonts]{amssymb}
\end{verbatim}
 or use the following workaround for reals, natural and complex: 
\begin{verbatim}
\newcommand{\RR}{I\!\!R} %real numbers
\newcommand{\Nat}{I\!\!N} %natural numbers 
\newcommand{\CC}{I\!\!\!\!C} %complex numbers
\end{verbatim}

\item Sometimes the problematic fonts are used in figures
included in LaTeX files. The ghostscript program \verb+eps2eps+ is the simplest
way to clean such figures. For black and white figures, slightly better
results can be achieved with program \verb+potrace+.
\end{itemize}
\item MSWord and Windows users (via PDF file):
\begin{itemize}
\item Install the Microsoft Save as PDF Office 2007 Add-in from
\url{http://www.microsoft.com/downloads/details.aspx?displaylang=en\&familyid=4d951911-3e7e-4ae6-b059-a2e79ed87041}
\item Select ``Save or Publish to PDF'' from the Office or File menu
\end{itemize}
\item MSWord and Mac OS X users (via PDF file):
\begin{itemize}
\item From the print menu, click the PDF drop-down box, and select ``Save
as PDF...''
\end{itemize}
\item MSWord and Windows users (via PS file):
\begin{itemize}
\item To create a new printer
on your computer, install the AdobePS printer driver and the Adobe Distiller PPD file from
\url{http://www.adobe.com/support/downloads/detail.jsp?ftpID=204} {\it Note:} You must reboot your PC after installing the
AdobePS driver for it to take effect.
\item To produce the ps file, select ``Print'' from the MS app, choose
the installed AdobePS printer, click on ``Properties'', click on ``Advanced.''
\item Set ``TrueType Font'' to be ``Download as Softfont''
\item Open the ``PostScript Options'' folder
\item Select ``PostScript Output Option'' to be ``Optimize for Portability''
\item Select ``TrueType Font Download Option'' to be ``Outline''
\item Select ``Send PostScript Error Handler'' to be ``No''
\item Click ``OK'' three times, print your file.
\item Now, use Adobe Acrobat Distiller or ps2pdf to create a PDF file from
the PS file. In Acrobat, check the option ``Embed all fonts'' if
applicable.
\end{itemize}

\end{itemize}
If your file contains Type 3 fonts or non embedded TrueType fonts, we will
ask you to fix it. 

\subsection{Margins in LaTeX}
 
Most of the margin problems come from figures positioned by hand using
\verb+\special+ or other commands. We suggest using the command
\verb+\includegraphics+
from the graphicx package. Always specify the figure width as a multiple of
the line width as in the example below using .eps graphics
\begin{verbatim}
   \usepackage[dvips]{graphicx} ... 
   \includegraphics[width=0.8\linewidth]{myfile.eps} 
\end{verbatim}
or % Apr 2009 addition
\begin{verbatim}
   \usepackage[pdftex]{graphicx} ... 
   \includegraphics[width=0.8\linewidth]{myfile.pdf} 
\end{verbatim}
for .pdf graphics. 
See section 4.4 in the graphics bundle documentation (\url{http://www.ctan.org/tex-archive/macros/latex/required/graphics/grfguide.ps}) 
 
A number of width problems arise when LaTeX cannot properly hyphenate a
line. Please give LaTeX hyphenation hints using the \verb+\-+ command.


\subsubsection*{Acknowledgments}

Use unnumbered third level headings for the acknowledgments. All
acknowledgments go at the end of the paper. Do not include 
acknowledgments in the anonymized submission, only in the 
final paper. 
\subsubsection*{References}

References follow the acknowledgments. Use unnumbered third level heading for
the references. Any choice of citation style is acceptable as long as you are
consistent. It is permissible to reduce the font size to `small' (9-point) 
when listing the references. {\bf Remember that this year you can use
a ninth page as long as it contains \emph{only} cited references.}

\small{
[1] Alexander, J.A. \& Mozer, M.C. (1995) Template-based algorithms
for connectionist rule extraction. In G. Tesauro, D. S. Touretzky
and T.K. Leen (eds.), {\it Advances in Neural Information Processing
Systems 7}, pp. 609-616. Cambridge, MA: MIT Press.

[2] Bower, J.M. \& Beeman, D. (1995) {\it The Book of GENESIS: Exploring
Realistic Neural Models with the GEneral NEural SImulation System.}
New York: TELOS/Springer-Verlag.

[3] Hasselmo, M.E., Schnell, E. \& Barkai, E. (1995) Dynamics of learning
and recall at excitatory recurrent synapses and cholinergic modulation
in rat hippocampal region CA3. {\it Journal of Neuroscience}
{\bf 15}(7):5249-5262.
}

\end{document}

