\documentclass{article} % For LaTeX2e
\usepackage{nips12submit_e,times}
\usepackage{hyperref}
\usepackage[margin=1in]{geometry}
%\documentstyle[nips12submit_09,times,art10]{article} % For LaTeX 2.09


 \title{Digit Recognition Using KNN and SVM}


\author{
Harnoor Singh \\
Department of Computer Science \& Engineering\\
University of Washington \\
\texttt{hsingh@cs.washington.edu} \\
\And
Brian Walker \\
Department of Computer Science \& Engineering \\
University of Washington \\
\texttt{bdwalker@cs.washington.edu} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}
\maketitle

\section{Objective}

As described in our project proposal, we are using the Kaggle digit dataset to classify written numbers.

Our goal is to implement digit recognition using K Nearest Neighbors (KNN) and a Support Vector Machine (SVM) and compare the two approaches. A stretch objective is to enable data that isn't a part of the Kaggle dataset to work with our algorithms. This would require some form of normalization in the input image for consistency.

\section{Progress}

\subsection{KNN}

We have made significant progress in both the KNN algorithm and the SVM algorithm. Our KNN algorithm is completely implemented as is cross validation for it. 

To compute the K nearest neighbors, we take the euclidean difference between the feature we are classifying, $X_1$, and every feature in our training set.

\begin{center}
$\sum\limits_{X_2 \exists N} {(X1 - X2)^2}$
\end{center}

Once we have calculated the K closest features, a simple voting method is used to classify $X_1$.

In order to select a value of K we do cross validation on a subset of the training set. We begin by passing a list of potential K values we are considering. For each item, $K_i$ in this list, we hold out $K_i$ samples from our training set and construct our classifier. We then attempt to classify the $K_i$ samples and record the error rate. 

The K value that led to the lowest error rate is used to build our final classifier. The result of our cross validation can be seen in Table 1 below.

\begin{table}[ht]
\caption{Cross Validation Selection of K} % title of Table
\centering  % used for centering table
\begin{tabular}{c c} 
\hline\hline
K & Error \\ [1.0ex]
\hline 
1 & 135 \\
2 & 164 \\
3 & 137 \\
4 & 148 \\
5 & 144 \\
10 & 163 \\
15 & 176 \\
20 & 191 \\ [1ex]
\hline
\end{tabular}
\label{table:nonlin}
\end{table}

\subsection{SVM}

The SVM implementations we have worked with previously have involved only two classes. Because we have to classify the digits 0-9, we need to create an SVM that can classify from a broader range. 

We are in the process of implementing a one-vs-one classifier. We train $n choose 2$ SVMs which compare two numbers. For example, one SVM would classify a digit as either a 1 or a 2. Another would classify a digit as a 1 or a 3, and so on. We get a prediction from all of these classifiers and take a vote to see which digit was most likely based on our SVMs. 

In our training step, every time we make a mistake we log it. Future predictions are made based on past mistakes.

\begin{center}
$Classification = sign(C * \sum\limits_{m \exists Mistakes} {(Y_m * k(X_m, X))})$
\end{center}

The biggest challenge thus far has been deciding how to regularize our SVM without relying on the weights. Because we use the kernel trick, the weights are never explicitly stored. 

\section{Future Work}

Our primary focus moving forward is to get our SVM implementation working. Most of the structure is in place, however we need to decide on our method of regularization. Once we have the regularization done we can analyze the effectiveness of our SVM.

For KNN it might be beneficial to attemp to increase performance. Classifying each sample takes about 1 second, and with the testing dataset holding about 50,000 samples it takes several hours to classify all the points. Possible areas of speedup are a better algorithm for finding the nearest neighbors or parallelizing the nearest neighbor search.


\begingroup
\renewcommand{\section}[2]{}%
%\renewcommand{\chapter}[2]{}% for other classes
\bibliographystyle{unsrt}
\bibliography{references}	
\endgroup


\end{document}

